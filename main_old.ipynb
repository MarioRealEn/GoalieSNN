{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "plt.gray()\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "from metavision_core.event_io import EventsIterator, RawReader\n",
    "from metavision_sdk_core import BaseFrameGenerationAlgorithm, ColorPalette\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "import pandas as pd\n",
    "from network import SCNN\n",
    "from simulator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 14.0      # field width (m)\n",
    "L = 11.0       # field length (m)\n",
    "\n",
    "field = Field(W, L, 2.4, 1)\n",
    "\n",
    "\n",
    "Vmax = 5    # maximum speed (m/s)\n",
    "R = 0.11       # radius of the ball (m) (11 - 11.5 cm)\n",
    "margin = 2\n",
    "constraints_go_in = [\n",
    "    lambda params: 0 < params[\"lx\"] < params[\"field\"].W,  # Landing X within bounds\n",
    "    lambda params: params[\"ly\"] < params[\"field\"].L,  # Landing Y within bounds\n",
    "    lambda params: params[\"tf\"] > 0.3,          # Minimum flight time\n",
    "    lambda params: 0< params[\"t_y0\"] < 5,          # Maximum time to reach X\n",
    "    lambda params: - (params[\"field\"].GW/2) < params[\"x_y0\"] - params[\"field\"].center[0] < params[\"field\"].GW/2,  # Ball should go through the goal or near it\n",
    "    lambda params: params[\"R\"] <= params[\"z_y0\"] < params[\"field\"].GH/2,  # Ball should go through the goal or near it\n",
    "]\n",
    "\n",
    "constraints_almost_go_in = [\n",
    "    lambda params: 0 < params[\"lx\"] < params[\"field\"].W,  # Landing X within bounds\n",
    "    lambda params: params[\"ly\"] < params[\"field\"].L,  # Landing Y within bounds\n",
    "    lambda params: params[\"tf\"] > 0.3,          # Minimum flight time\n",
    "    lambda params: 0< params[\"t_y0\"] < 5,          # Maximum time to reach X\n",
    "    lambda params: - (params[\"field\"].GW/2 + margin) < params[\"x_y0\"] - params[\"field\"].center[0] < - params[\"field\"].GW/2 or params[\"field\"].GW/2 < params[\"x_y0\"] - params[\"field\"].center[0] < params[\"field\"].GW/2 + margin or params[\"field\"].GH/2 <= params[\"z_y0\"] < params[\"field\"].GH/2 + margin,  # Ball should go through the goal or near it\n",
    "]\n",
    "\n",
    "constraints_go_out = [\n",
    "    lambda params: 0 < params[\"lx\"] < params[\"field\"].W,  # Landing X within bounds\n",
    "    lambda params: params[\"ly\"] < params[\"field\"].L,  # Landing Y within bounds\n",
    "    lambda params: params[\"tf\"] > 0.3,          # Minimum flight time\n",
    "    lambda params: 0< params[\"t_y0\"] < 5,          # Maximum time to reach X\n",
    "]\n",
    "\n",
    "traj_go_in_gen = TrajectoryGenerator(constraints_go_in, R, field, Vmax)\n",
    "traj_almost_go_in_gen = TrajectoryGenerator(constraints_almost_go_in, R, field, Vmax)\n",
    "traj_go_out_gen = TrajectoryGenerator(constraints_go_out, R, field, Vmax)\n",
    "\n",
    "fps = 200\n",
    "\n",
    "camera_pos = np.array([field.center[0], 0, 0.7])          # Camera position in world space\n",
    "camera_target = np.array([field.center[0], field.center[1], camera_pos[2]])        # Where the camera is looking (center of field) It would be good to transform this into an angle and assume verticality\n",
    "orientation = Camera.get_orientation(camera_pos, camera_target)\n",
    "img_width, img_height = 640, 480               # Image resolution (in pixels)\n",
    "focal_length = 800                             # Focal length in pixels (adjust as needed)\n",
    "\n",
    "camera = Camera(camera_pos, orientation, focal_length, img_width, img_height, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_go_in = np.array(traj_go_in_gen.generate_velocities())\n",
    "init_almost_go_in = np.array(traj_almost_go_in_gen.generate_velocities())\n",
    "init_go_out = np.array(traj_go_out_gen.generate_velocities())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Videos in IsaacSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Lightings\n",
    "# Robot moving in the background\n",
    "# Goalie moving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Videos to Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SNN\n",
    "## Load events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Event_camera_data\\\\recording_2025-02-20_13-38-07.raw',\n",
       " 'Event_camera_data\\\\recording_2025-02-20_13-41-38.raw',\n",
       " 'Event_camera_data\\\\recording_2025-02-20_13-45-16.raw',\n",
       " 'Event_camera_data\\\\recording_2025-02-20_13-47-09.raw']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "dir_paths = glob.glob('Event_camera_data\\\\*.raw', recursive=True)\n",
    "dir_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_events= 'Event_camera_data\\\\recording_2025-02-20_13-38-07.raw'\n",
    "raw_data = RawReader(path_to_events)\n",
    "height, width = raw_data.get_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_time_volume(raw_data, start_t_us, delta_t_us):\n",
    "    raw_data.reset()\n",
    "    if start_t_us > raw_data.current_time:\n",
    "        raw_data.seek_time(start_t_us)\n",
    "    events_vol = raw_data.load_delta_t(delta_t_us)\n",
    "    # events_vol['t'] -= int(start_t_us)\n",
    "    return events_vol\n",
    "def viz_events(events, height, width):\n",
    "    img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    # check that all events are within width-heigh\n",
    "    ids = np.logical_and(events['y'] < height, events['x'] < width) \n",
    "    events = events[ids]\n",
    "    events_plus = events[events['p']>0]\n",
    "    events_minus = events[events['p']==0]\n",
    "    img[events_plus['y'], events_plus['x'], 0] = 255\n",
    "    img[events_minus['y'], events_minus['x'], 2] = 255\n",
    "    return img\n",
    "def gen_imgs(raw_data, start_t_us, end_t_us, delta_t_us):\n",
    "    imgs = []\n",
    "\n",
    "    for t in range(int(start_t_us), int(end_t_us), int(delta_t_us)):\n",
    "        events = read_time_volume(raw_data, t, delta_t_us)\n",
    "        img = viz_events(events, height, width)\n",
    "        imgs.append(img)\n",
    "    imgs = torch.tensor(imgs, dtype=torch.float32)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 720, 1280, 3]) torch.Size([40, 720, 1280, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\realenriquem\\AppData\\Local\\Temp\\ipykernel_2744\\2324584307.py:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\bld\\libtorch_1738203676394\\work\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  imgs = torch.tensor(imgs, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "imgs = gen_imgs(raw_data, 56e6, 58e6, 10e3)\n",
    "training_ratio = 0.8\n",
    "training_size = int(training_ratio*imgs.shape[0])\n",
    "train_data = imgs[:training_size]\n",
    "test_data = imgs[training_size:]\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_goal_divisions = 10\n",
    "scnn = SCNN(n_goal_divisions)\n",
    "scnn.train(train_data, test_data, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate SNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "balltracking_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
