{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19cfeb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import snntorch as snn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from snntorch import spikeplot as splt\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import network\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "import data as dt\n",
    "\n",
    "\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\" # for debugging on GPU\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0087f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5b388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21531 rows from dataset_python_sim\\positions_10ms.csv\n",
      "Found 156 sequences in dataset_python_sim\\positions_10ms.csv\n",
      "Shape of the images: torch.Size([2, 90, 160])\n",
      "Label shape: None\n",
      "Split sizes: train=109, val=23, test=24, total=156\n",
      "Final dataset split='train' size: 109\n",
      "Loaded 21531 rows from dataset_python_sim\\positions_10ms.csv\n",
      "Found 156 sequences in dataset_python_sim\\positions_10ms.csv\n",
      "Shape of the images: torch.Size([2, 90, 160])\n",
      "Label shape: None\n",
      "Split sizes: train=109, val=23, test=24, total=156\n",
      "Final dataset split='test' size: 24\n",
      "Loaded 21531 rows from dataset_python_sim\\positions_10ms.csv\n",
      "Found 156 sequences in dataset_python_sim\\positions_10ms.csv\n",
      "Shape of the images: torch.Size([2, 90, 160])\n",
      "Label shape: None\n",
      "Split sizes: train=109, val=23, test=24, total=156\n",
      "Final dataset split='val' size: 23\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'dataset_python_sim'\n",
    "accumulation_time = 10 # ms\n",
    "quantization = 8\n",
    "batch_size = 4\n",
    "dataset_type = \"all\"\n",
    "labels = ['x_cam', 'y_cam', 'R_cam', 'in_fov']\n",
    "trainset = dt.Tracking3DVideoDataset(dataset_path, accumulation_time, quantization = quantization, split='train', dataset_type=dataset_type, labels=labels)\n",
    "testset = dt.Tracking3DVideoDataset(dataset_path, accumulation_time, quantization = quantization, split='test', dataset_type=dataset_type, labels=labels)\n",
    "validationset = dt.Tracking3DVideoDataset(dataset_path, accumulation_time, quantization = quantization, split='val', dataset_type=dataset_type, labels=labels)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=trainset.collate_fn)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=testset.collate_fn)\n",
    "valid_loader = DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=validationset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc0ad86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model with weighted average: False\n",
      "Flattened feature size: 14080\n",
      "Number of x_cam bins: 161\n",
      "Number of y_cam bins: 91\n",
      "Number of R_cam bins: 101\n",
      "Number of in_fov bins: 1\n",
      "Evaluating video classification tracker\n",
      "Average Error for x_cam: 7.2228 pixels\n",
      "Average Error for y_cam: 5.9939 pixels\n",
      "Average Error for R_cam: 0.6192 pixels\n",
      "Average Error for in_fov: 0.0823 pixels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.2228027 , 5.99385372, 0.61923786, 0.08226998])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = network.load_model(\"models/VideoClassification_w_confidence_finetuned_lower_lr_q8_5ts_10e.pt\", network.SCNNVideoClassification, trainset=trainset, device=device)\n",
    "model.evaluate(valid_loader, device, num_steps = 5, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa039d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_with_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
